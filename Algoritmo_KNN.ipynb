{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqr/68zqLoJ3J4uHQbSeVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattJCR/Algoritmo-KNN/blob/master/Algoritmo_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Algoritmo KNN**\n",
        "\n",
        "El algoritmo KNN es un algoritmo de aprendizaje de máquinas utilizado en minería de datos y análisis de datos. La idea principal detrás de este algoritmo es encontrar el grupo de puntos de datos más cercanos (conocidos como \"vecinos\") a un nuevo punto de datos, y utilizar ese grupo para predecir la clase del nuevo punto de datos. Esto se logra calculando la distancia entre el nuevo punto de datos y cada uno de los puntos de datos en el conjunto de datos utilizando una medida de distancia como la distancia euclidiana o la distancia de Manhattan. Luego, se seleccionan los k puntos con la menor distancia al nuevo punto de datos, y esos puntos se utilizan para predecir la clase del nuevo punto de datos.\n",
        "\n",
        "Aquí hay un ejemplo de implementación del algoritmo KNN en Python utilizando el conjunto de datos Iris y un clasificador KNN:"
      ],
      "metadata": {
        "id": "2NHSIOUktHaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsbZor30sFCf",
        "outputId": "3b3a0339-82cd-4384-f2ad-5203cf129ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [2]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create the KNN classifier\n",
        "# Specify that 3 neighbors should be used and the Euclidean distance should be used\n",
        "knn = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
        "\n",
        "# Train the classifier with the data\n",
        "knn.fit(iris.data, iris.target)\n",
        "\n",
        "# Make a prediction for a new data point\n",
        "# In this case, the measurements of an Iris flower with petal and sepal lengths and widths equal to 5 are used\n",
        "prediction = knn.predict([[5, 5, 5, 5]])\n",
        "\n",
        "# Print the prediction result\n",
        "print(\"Prediction:\", prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clasificador de vecinos de radio**\n",
        "\n",
        "El clasificador de vecinos de radio es una variante del algoritmo KNN que utiliza un radio fijo para determinar los vecinos de un nuevo punto de datos. En lugar de seleccionar los k puntos con la menor distancia al nuevo punto de datos, el clasificador de vecinos de radio selecciona todos los puntos dentro del radio especificado del nuevo punto de datos.\n",
        "\n",
        "Aquí hay un ejemplo de implementación del clasificador de vecinos de radio en Python utilizando el conjunto de datos Iris:\n",
        "\n",
        "```\n",
        "# Tiene formato de código\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Zj_vRiVOtL1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create the radius neighbors classifier\n",
        "# Specify that a radius of 6.0 should be used and the Manhattan distance should be used\n",
        "rnc = RadiusNeighborsClassifier(radius=6.0, metric=\"manhattan\")\n",
        "\n",
        "# Train the classifier with the data\n",
        "rnc.fit(iris.data, iris.target)\n",
        "\n",
        "# Make a prediction for a new data point\n",
        "# In this case, the measurements of an Iris flower with petal and sepal lengths and widths equal to 5 are used\n",
        "prediction = rnc.predict([[5, 5, 5, 5]])\n",
        "\n",
        "# Print the prediction result\n",
        "print(\"Prediction:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SuSmUb-tOkS",
        "outputId": "bd88d8ac-1264-4eee-bc34-29203f66b33d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Error cuadrático medio**\n",
        "\n",
        "El error cuadrático medio (MSE) es una métrica que se utiliza para evaluar el desempeño de un modelo de aprendizaje de máquinas. El MSE se calcula como el promedio de las diferencias cuadradas entre los valores predecidos y los verdaderos valores. En otras palabras, mide la cantidad promedio en la que los valores predecidos se desvían de los valores verdaderos. Un MSE más bajo indica un ajuste mejor del modelo a los datos.\n",
        "\n",
        "Aquí hay un ejemplo de implementación del MSE en Python utilizando el conjunto de datos Iris y un clasificador de vecinos de radio:"
      ],
      "metadata": {
        "id": "xAzzRcgttbMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create the radius neighbors classifier\n",
        "# Specify that a radius of 0.5 should be used and the Euclidean distance should be used\n",
        "rnc = RadiusNeighborsClassifier(radius=5.0, metric=\"manhattan\")\n",
        "\n",
        "# Split the dataset into a training set and a test set\n",
        "X_train = iris.data[:100]\n",
        "y_train = iris.target[:100]\n",
        "X_test = iris.data[100:]\n",
        "y_test = iris.target[100:]\n",
        "\n",
        "# Train the classifier with the training data\n",
        "rnc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the test data\n",
        "predictions = rnc.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "\n",
        "# Print the mean squared error\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFLKmh89teWo",
        "outputId": "ae062317-b3f2-416e-e12d-24b56ccd5de2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En resumen:\n",
        "* El algoritmo KNN es un algoritmo de aprendizaje de máquinas que se utiliza para clasificar datos.\n",
        "* El algoritmo funciona seleccionando los k puntos de datos más cercanos a un nuevo punto de datos y asignando al nuevo punto la etiqueta de la mayoría de los puntos seleccionados.\n",
        "* La distancia entre puntos de datos se puede calcular utilizando diferentes métricas, como la distancia Euclidiana o la distancia de Manhattan.\n",
        "* El clasificador de vecinos de radio es una variante del algoritmo KNN que utiliza un radio fijo para determinar los vecinos de un nuevo punto de datos.\n",
        "* El error cuadrático medio (MSE) es una métrica que se utiliza para evaluar el desempeño de un modelo de aprendizaje de máquinas. Un MSE más bajo indica un ajuste mejor del modelo a los datos.\n",
        "\n"
      ],
      "metadata": {
        "id": "W4xfRFElwDQ7"
      }
    }
  ]
}